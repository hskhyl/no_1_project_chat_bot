{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_9572\\3627484799.py:9: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import deque\n",
    "from html.parser import HTMLParser\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import pandas as pd\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaw_dict_4.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m#단어사전 불러오기\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('law_dict_4.csv', index_col=0) #단어사전 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaw_dict_4.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m#단어사전 불러오기\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#순서대로 칼럼 넣기\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#  cl100k_base는 토크나이저다. 임베딩과는 큰 관련이 없다.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m tiktoken\u001b[38;5;241m.\u001b[39mget_encoding(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl100k_base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\a\\Documents\\GitHub\\no_1_project_chat_bot\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:6307\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6306\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6309\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\a\\Documents\\GitHub\\no_1_project_chat_bot\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:813\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    812\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 813\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\a\\Documents\\GitHub\\no_1_project_chat_bot\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:239\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\Users\\a\\Documents\\GitHub\\no_1_project_chat_bot\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "\"\"\"토큰 계산 코드\"\"\"\n",
    "import tiktoken\n",
    "df = pd.read_csv('law_dict_4.csv', index_col=0) #단어사전 불러오기\n",
    "df.columns = ['title', 'text'] #순서대로 칼럼 넣기\n",
    "\n",
    "#  cl100k_base는 토크나이저다. 임베딩과는 큰 관련이 없다.\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# 소요되는 토큰을 각 칼럼에 저장하기. apply 함수가 쓰였다!\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 히스토그램으로 그려서 보기\n",
    "df.n_tokens.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"본격적인 임베딩 시작\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv('../../.env'))  #.env 파일 찾기\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 됐으면 바로 다 집어 넣어 ~\n",
    "# df라는 데이터 프레임에 칼럼 embeddings를 넣을 건데 그건 각각의 임베딩 값이 된다.\n",
    "df['embeddings'] = df.text.apply(lambda x: client.embeddings.create(input=x, model='text-embedding-ada-002').data[0].embedding)\n",
    "df.to_csv('law_dict_inclue_embeddings.csv') #embeddings칼럼이 추가된 df를 따로 저장해둔다.\n",
    "df.head() #견본을 살펴본다. 잘됐나?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"이제부터는 데이터프레임을 임베딩값 연산 편하게 apply해서 np.array로 변환해줄거임 그게 연산 최고\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#아까 저장했던 embeedings칼럼이 들어간 df를 df으로 다시 불러온다. index_col=0으로 두어 쓸데없는 칼럼 인덱스 추가 안한다.\n",
    "df=pd.read_csv('law_dict_inclue_embeddings.csv', index_col=0)\n",
    "\n",
    "# 임베딩스 열의 임베딩 값들을 np.array를 통해 다시 배열해 준다 > 연산에 효율성이 좋다. 여기서 eval 쓰는건 이거 파이썬 값인걸\n",
    "# 가끔 인지 못하는 경우가 있어서 확실하게 eval 해주는 것.\n",
    "df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)\n",
    "\n",
    "#견본을 살펴보자 array 잘 됐나?\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_context라는 함수는 question과 df, max_len을 인자로 가지는데 여기서 max_len은 1800으로 정해져 있다.\n",
    "def create_context(\n",
    "    question, df, max_len=1800\n",
    "):\n",
    "    \"\"\"\n",
    "    데이터 프레임으로부터 가장 유사한 문맥을 찾아서 질문에 대한 문맥을 만든다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 질문으로부터 임베딩 값을 만든다.\n",
    "    q_embeddings = client.embeddings.create(input=question, model='text-embedding-ada-002').data[0].embedding\n",
    "    \n",
    "\n",
    "    # df상의 임베딩 값들과 qestion의 임베딩 값들의 코사인 유사도를 통해 distance를 계산한다.\n",
    "    # cosine similarity: 문자열끼리 유사도 비교하는 것.\n",
    "    df[\"distances\"] = df[\"embeddings\"].apply(lambda x: cosine(q_embeddings, x))\n",
    "\n",
    "\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "\n",
    "    # 거리순으로 정렬하고, 문맥이 너무 길어지기 전까지만 텍스트를 문맥에 추가한다.\n",
    "    #distances 칼럼의 값들을 거리순으로 정렬시킨다.\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "        \n",
    "\n",
    "        # 현재 토큰 수에 텍스트 길이를 더한다.\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "        \n",
    "        # 그렇게 더해진 현재 토큰수는 곧 문맥이될 터인데, 그것이 max_len으로 설정한 값보다 길어지면, break하고\n",
    "        # 밑에 바로 return으로 넘어간다.\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "        \n",
    "\n",
    "        # 하지만 그렇지 않다면, 문맥에 추가한다. else안 쓴거는 그렇게 안해도 그냥 if아니면 넘어가서 다음문장 실행이니까\n",
    "        returns.append(row[\"text\"])       #해당 인덱스(행)의 \"text\"를 문맥(returns)에 추가시켜준다.\n",
    "\n",
    "    # 그렇게 결국 create_context는 문맥을 뱉어낸다.\n",
    "    return \"\\n\\n###\\n\\n\".join(returns)  \n",
    "\n",
    "\n",
    "# 이 함수가 하는 일 다시 정리해보자.\n",
    "# 1. 질문이 들어오면 질문을 임베딩한다. 즉, 숫자 표현으로 바꿔준다.\n",
    "# 2. 모든 문장들의 임베딩과 질문의 임베딩 사이의 거리를 계산한다.\n",
    "# 3. 문맥이 너무 길어지면 안되니까, 가장 거리가 가까운 문장부터 차례대로 문맥에 추가한다.\n",
    "# 4. 문맥을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_context라는 함수는 인자로 question, df, max_len 총 세개를 가지나, max_len은 이미 1800으로 고정이다.\n",
    "print(create_context('근로자란?', df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def answer_question(df, model=\"gpt-3.5-turbo\", question, max_len=1800, debug =False):\n",
    "    \"\"\"\n",
    "    데이터 프레임 텍스트에서 가장 유사한 문맥을 기반으로 질문에 답한다.\n",
    "    \"\"\"\n",
    "    context = create_context(question, df, max_len=max_len)\n",
    "\n",
    "    if debug:\n",
    "\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\n\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\n---\\n\\n Question: {question}\"}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_question(df, question=\"근로자란?\", debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
